{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# This is necessary to recognize the modules\n",
    "import os\n",
    "import sys\n",
    "from decimal import Decimal\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "sys.path.append(root_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from core.data_sources.clob import CLOBDataSource\n",
    "\n",
    "clob = CLOBDataSource()\n",
    "clob.load_candles_cache(root_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "candles = list(clob.candles_cache.values())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# First, let's prepare the close prices and calculate returns\n",
    "pair_returns = {}\n",
    "for candle in candles:\n",
    "    df = candle.data\n",
    "    if df is not None and not df.empty:\n",
    "        # Get the trading pair from the DataFrame\n",
    "        pair_name = candle.trading_pair\n",
    "        # Calculate returns using pct_change\n",
    "        returns = df['close'].pct_change().dropna()\n",
    "        pair_returns[pair_name] = returns\n",
    "\n",
    "# Create a list of all pairs\n",
    "pairs = list(pair_returns.keys())\n",
    "n_pairs = len(pairs)\n",
    "\n",
    "# Initialize the cointegration matrix\n",
    "cointegration_matrix = pd.DataFrame(\n",
    "    np.zeros((n_pairs, n_pairs)),\n",
    "    index=pairs,\n",
    "    columns=pairs\n",
    ")\n",
    "\n",
    "# Calculate cointegration p-values for each pair combination\n",
    "for i in tqdm(range(n_pairs)):\n",
    "    for j in range(i+1, n_pairs):\n",
    "        pair1, pair2 = pairs[i], pairs[j]\n",
    "        \n",
    "        # Get the returns series\n",
    "        series1 = pair_returns[pair1]\n",
    "        series2 = pair_returns[pair2]\n",
    "        \n",
    "        # Align the series to have the same index\n",
    "        series1, series2 = series1.align(series2, join='inner')\n",
    "        \n",
    "        if len(series1) > 0:\n",
    "            # Perform cointegration test\n",
    "            _, p_value, _ = coint(series1, series2)\n",
    "            \n",
    "            # Fill the matrix (make it symmetric)\n",
    "            cointegration_matrix.iloc[i, j] = p_value\n",
    "            cointegration_matrix.iloc[j, i] = p_value\n",
    "\n",
    "# Fill diagonal with 1s\n",
    "np.fill_diagonal(cointegration_matrix.values, 1)\n",
    "\n",
    "# Display the results\n",
    "print(\"Cointegration p-values matrix:\")\n",
    "print(\"(Lower p-values indicate stronger cointegration)\")\n",
    "cointegration_matrix"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "from scipy.spatial.distance import squareform\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# Convert p-values to distances (same as before)\n",
    "distance_matrix = -np.log(cointegration_matrix)\n",
    "distance_matrix[np.isinf(distance_matrix)] = np.max(distance_matrix[~np.isinf(distance_matrix)]) * 2\n",
    "distances_condensed = squareform(distance_matrix)\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "Z = linkage(distances_condensed, method='ward')\n",
    "\n",
    "# Plot dendrogram using plotly\n",
    "fig = ff.create_dendrogram(\n",
    "    Z,\n",
    "    orientation='left',\n",
    ")\n",
    "fig.update_layout(\n",
    "    title='Hierarchical Clustering Dendrogram',\n",
    "    width=1000,\n",
    "    height=800,\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Choose number of clusters and create cluster assignments (same as before)\n",
    "n_clusters = 5\n",
    "clusters = fcluster(Z, n_clusters, criterion='maxclust')\n",
    "\n",
    "# Create DataFrame and calculate metrics (same as before)\n",
    "cluster_df = pd.DataFrame({\n",
    "    'trading_pair': pairs,\n",
    "    'cluster': clusters\n",
    "})\n",
    "\n",
    "# Calculate volume metrics (same as before)\n",
    "volume_metrics = {}\n",
    "for candle in candles:\n",
    "    if candle.data is not None and not candle.data.empty:\n",
    "        pair_name = candle.trading_pair\n",
    "        avg_volume = candle.data['volume'].mean()\n",
    "        volume_stability = candle.data['volume'].std() / avg_volume\n",
    "        volume_metrics[pair_name] = {\n",
    "            'avg_volume': avg_volume,\n",
    "            'volume_stability': volume_stability\n",
    "        }\n",
    "\n",
    "cluster_df['avg_volume'] = cluster_df['trading_pair'].map(lambda x: volume_metrics.get(x, {}).get('avg_volume', 0))\n",
    "cluster_df['volume_stability'] = cluster_df['trading_pair'].map(lambda x: volume_metrics.get(x, {}).get('volume_stability', float('inf')))\n",
    "\n",
    "# Create scatter plot using plotly\n",
    "fig = px.scatter(\n",
    "    cluster_df,\n",
    "    x='avg_volume',\n",
    "    y='volume_stability',\n",
    "    color='cluster',\n",
    "    hover_data=['trading_pair'],\n",
    "    log_x=True,\n",
    "    log_y=True,\n",
    "    title='Clusters by Volume Metrics'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Average Volume',\n",
    "    yaxis_title='Volume Stability (lower is better)',\n",
    "    width=1000,\n",
    "    height=600\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Create heatmap of cointegration matrix using plotly\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=cointegration_matrix,\n",
    "    x=pairs,\n",
    "    y=pairs,\n",
    "    colorscale='RdBu_r',\n",
    "    zmin=0,\n",
    "    zmax=0.05\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Cointegration P-values Heatmap (Darker colors indicate stronger cointegration)',\n",
    "    width=1000,\n",
    "    height=1000,\n",
    "    xaxis_tickangle=-45\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Select top pairs (same function as before)\n",
    "def select_top_pairs(cluster_df, n_pairs_per_cluster=3):\n",
    "    selected_pairs = []\n",
    "    for cluster_num in cluster_df['cluster'].unique():\n",
    "        cluster_pairs = cluster_df[cluster_df['cluster'] == cluster_num].copy()\n",
    "        cluster_pairs['volume_score'] = cluster_pairs['avg_volume'] / cluster_pairs['volume_stability']\n",
    "        top_pairs = cluster_pairs.nlargest(n_pairs_per_cluster, 'volume_score')\n",
    "        selected_pairs.append(top_pairs)\n",
    "    return pd.concat(selected_pairs)\n",
    "\n",
    "# Select and display top pairs\n",
    "top_pairs = select_top_pairs(cluster_df, n_pairs_per_cluster=3)\n",
    "\n",
    "print(\"\\nTop pairs by cluster:\")\n",
    "for cluster_num in top_pairs['cluster'].unique():\n",
    "    print(f\"\\nCluster {cluster_num}:\")\n",
    "    cluster_result = top_pairs[top_pairs['cluster'] == cluster_num]\n",
    "    print(cluster_result[['trading_pair', 'avg_volume', 'volume_stability', 'volume_score']])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cluster_df.iloc[307]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_clusters_timeseries(candles, Z, pairs, cut_height=None, n_clusters=None):\n",
    "    \"\"\"\n",
    "    Create a line plot of price changes over time, colored by clusters.\n",
    "    \n",
    "    Args:\n",
    "        candles: List of candle dataframes\n",
    "        Z: Linkage matrix from hierarchical clustering\n",
    "        pairs: List of trading pair names\n",
    "        cut_height: Height to cut the dendrogram (if None, n_clusters is used)\n",
    "        n_clusters: Number of clusters (used if cut_height is None)\n",
    "    \"\"\"\n",
    "    # Get clusters based on either cut_height or n_clusters\n",
    "    if cut_height is not None:\n",
    "        clusters = fcluster(Z, cut_height, criterion='distance')\n",
    "    else:\n",
    "        clusters = fcluster(Z, n_clusters, criterion='maxclust')\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    plot_data = []\n",
    "    for candle, pair in zip(candles, pairs):\n",
    "        if candle.data is not None and not candle.data.empty:\n",
    "            df = candle.data.copy()\n",
    "            # Calculate cumulative returns to show relative price movement\n",
    "            df['cum_returns'] = (1 + df['close'].pct_change()).cumprod()\n",
    "            df['trading_pair'] = pair\n",
    "            # Find the cluster for this pair\n",
    "            pair_cluster = clusters[pairs.index(pair)]\n",
    "            df['cluster'] = f'Cluster {pair_cluster}'\n",
    "            plot_data.append(df)\n",
    "    \n",
    "    # Combine all data\n",
    "    combined_df = pd.concat(plot_data)\n",
    "    \n",
    "    # Create line plot\n",
    "    fig = px.line(\n",
    "        combined_df,\n",
    "        x='timestamp',\n",
    "        y='cum_returns',\n",
    "        color='cluster',\n",
    "        line_group='trading_pair',\n",
    "        hover_data=['trading_pair', 'close'],\n",
    "        title=f'Cumulative Returns Over Time by Cluster ({\"Cut Height: \" + str(cut_height) if cut_height else \"Clusters: \" + str(n_clusters)})'\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title='Cumulative Returns (1 = start)',\n",
    "        width=1200,\n",
    "        height=800,\n",
    "        # showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Print cluster statistics\n",
    "    print(\"\\nCluster Statistics:\")\n",
    "    cluster_stats = combined_df.groupby('cluster').agg({\n",
    "        'cum_returns': ['mean', 'std', 'count'],\n",
    "        'trading_pair': 'nunique'\n",
    "    }).round(4)\n",
    "    print(cluster_stats)\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "# Alternative version with normalized prices for easier comparison\n",
    "def plot_clusters_timeseries_normalized(candles, Z, pairs, cut_height=None, n_clusters=None):\n",
    "    \"\"\"\n",
    "    Create a line plot of normalized prices over time, colored by clusters.\n",
    "    All prices are normalized to start at 1 for easier comparison.\n",
    "    \"\"\"\n",
    "    # Get clusters based on either cut_height or n_clusters\n",
    "    if cut_height is not None:\n",
    "        clusters = fcluster(Z, cut_height, criterion='distance')\n",
    "    else:\n",
    "        clusters = fcluster(Z, n_clusters, criterion='maxclust')\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    plot_data = []\n",
    "    for candle, pair in zip(candles, pairs):\n",
    "        if candle.data is not None and not candle.data.empty:\n",
    "            df = candle.data.copy()\n",
    "            # Normalize prices to start at 1\n",
    "            df['normalized_price'] = df['close'] / df['close'].iloc[0]\n",
    "            df['trading_pair'] = pair\n",
    "            # Find the cluster for this pair\n",
    "            pair_cluster = clusters[pairs.index(pair)]\n",
    "            df['cluster'] = f'Cluster {pair_cluster}'\n",
    "            plot_data.append(df)\n",
    "    \n",
    "    # Combine all data\n",
    "    combined_df = pd.concat(plot_data)\n",
    "    \n",
    "    # Create line plot\n",
    "    fig = px.line(\n",
    "        combined_df,\n",
    "        x='timestamp',\n",
    "        y='normalized_price',\n",
    "        color='cluster',\n",
    "        line_group='trading_pair',\n",
    "        hover_data=['trading_pair', 'close'],\n",
    "        title=f'Normalized Price Movement by Cluster ({\"Cut Height: \" + str(cut_height) if cut_height else \"Clusters: \" + str(n_clusters)})'\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title='Normalized Price (1 = start)',\n",
    "        width=1200,\n",
    "        height=800,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "# Example usage:\n",
    "# Using cumulative returns\n",
    "clusters = plot_clusters_timeseries(candles, Z, pairs, n_clusters=10)\n",
    "\n",
    "# Using normalized prices\n",
    "clusters = plot_clusters_timeseries_normalized(candles, Z, pairs, n_clusters=10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def select_representative_markets(candles, Z, pairs, n_clusters, top_n=1):\n",
    "    \"\"\"\n",
    "    Select representative markets from each cluster based on USD volume and volatility.\n",
    "    \n",
    "    Args:\n",
    "        candles: List of candle dataframes\n",
    "        Z: Linkage matrix from hierarchical clustering\n",
    "        pairs: List of trading pair names\n",
    "        n_clusters: Number of clusters to form\n",
    "        top_n: Number of markets per cluster\n",
    "    \"\"\"\n",
    "    # Get cluster assignments\n",
    "    clusters = fcluster(Z, n_clusters, criterion='maxclust')\n",
    "    \n",
    "    # Create base DataFrame with cluster assignments\n",
    "    cluster_df = pd.DataFrame({\n",
    "        'trading_pair': pairs,\n",
    "        'cluster': clusters\n",
    "    })\n",
    "    \n",
    "    # Calculate metrics for each market\n",
    "    market_metrics = []\n",
    "    for candle in candles:\n",
    "        if candle.data is not None and not candle.data.empty:\n",
    "            # Calculate USD volume by multiplying volume by price\n",
    "            usd_volume = candle.data['volume'] * candle.data['close']\n",
    "            \n",
    "            metrics = {\n",
    "                'trading_pair': candle.trading_pair,\n",
    "                'avg_usd_volume': usd_volume.mean(),\n",
    "                'volatility': candle.data['close'].pct_change().std(),\n",
    "                'price_mean': candle.data['close'].mean(),\n",
    "                'n_trades': len(candle.data),\n",
    "                'volume_stability': usd_volume.std() / usd_volume.mean() if usd_volume.mean() != 0 else float('inf')\n",
    "            }\n",
    "            market_metrics.append(metrics)\n",
    "    \n",
    "    # Create metrics DataFrame\n",
    "    metrics_df = pd.DataFrame(market_metrics)\n",
    "    \n",
    "    # Merge metrics with cluster assignments\n",
    "    cluster_df = cluster_df.merge(metrics_df, on='trading_pair', how='left')\n",
    "    \n",
    "    # Normalize metrics\n",
    "    for col in ['avg_usd_volume', 'volatility']:\n",
    "        cluster_df[f'{col}_normalized'] = (cluster_df[col] - cluster_df[col].min()) / (cluster_df[col].max() - cluster_df[col].min())\n",
    "    \n",
    "    # Calculate combined score (you can adjust weights here)\n",
    "    cluster_df['score'] = (\n",
    "        cluster_df['avg_usd_volume_normalized'] * 0.6 +  # Higher weight for volume\n",
    "        cluster_df['volatility_normalized'] * 0.4        # Lower weight for volatility\n",
    "    )\n",
    "    \n",
    "    # Select top markets from each cluster\n",
    "    selected_markets = []\n",
    "    for cluster_num in range(1, n_clusters + 1):\n",
    "        cluster_markets = cluster_df[cluster_df['cluster'] == cluster_num].copy()\n",
    "        top_markets = cluster_markets.nlargest(top_n, 'score')\n",
    "        selected_markets.append(top_markets)\n",
    "    \n",
    "    selected_df = pd.concat(selected_markets)\n",
    "    \n",
    "    # Sort by cluster and score\n",
    "    selected_df = selected_df.sort_values(['cluster', 'score'], ascending=[True, False])\n",
    "    \n",
    "    # Create visualization\n",
    "    fig = px.scatter(\n",
    "        cluster_df[cluster_df['trading_pair'].isin(selected_df['trading_pair'])],\n",
    "        x='avg_usd_volume',\n",
    "        y='volatility',\n",
    "        color='cluster',\n",
    "        text='trading_pair',\n",
    "        title=f'Market Selection by USD Volume and Volatility (Top {top_n} per cluster)',\n",
    "        hover_data=['trading_pair', 'avg_usd_volume', 'volatility', 'volume_stability', 'score'],\n",
    "        log_x=True  # Use log scale for volume\n",
    "    )\n",
    "    \n",
    "    # Highlight selected markets\n",
    "    selected_pairs = selected_df['trading_pair'].tolist()\n",
    "    for pair in selected_pairs:\n",
    "        market_data = cluster_df[cluster_df['trading_pair'] == pair]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[market_data['avg_usd_volume'].iloc[0]],\n",
    "                y=[market_data['volatility'].iloc[0]],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    symbol='star',\n",
    "                    size=15,\n",
    "                    line=dict(width=2, color='black'),\n",
    "                    showscale=False\n",
    "                ),\n",
    "                name=f'Selected: {pair}',\n",
    "                showlegend=True,\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        width=1000,\n",
    "        height=600,\n",
    "        showlegend=True,\n",
    "        xaxis_title='Average USD Volume (log scale)',\n",
    "        yaxis_title='Volatility'\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"\\nSelected Markets by Cluster:\")\n",
    "    for cluster_num in range(1, n_clusters + 1):\n",
    "        print(f\"\\nCluster {cluster_num}:\")\n",
    "        cluster_results = selected_df[selected_df['cluster'] == cluster_num]\n",
    "        display_cols = ['trading_pair', 'avg_usd_volume', 'volatility', 'volume_stability', 'score']\n",
    "        \n",
    "        # Format the results for better readability\n",
    "        formatted_results = cluster_results[display_cols].copy()\n",
    "        formatted_results['avg_usd_volume'] = formatted_results['avg_usd_volume'].apply(lambda x: f\"${x:,.2f}\")\n",
    "        formatted_results['volatility'] = formatted_results['volatility'].apply(lambda x: f\"{x:.4f}\")\n",
    "        formatted_results['volume_stability'] = formatted_results['volume_stability'].apply(lambda x: f\"{x:.4f}\")\n",
    "        formatted_results['score'] = formatted_results['score'].apply(lambda x: f\"{x:.4f}\")\n",
    "        \n",
    "        print(formatted_results.to_string(index=False))\n",
    "    \n",
    "    return selected_df\n",
    "\n",
    "# Example usage:\n",
    "selected_markets = select_representative_markets(\n",
    "    candles=candles,\n",
    "    Z=Z,\n",
    "    pairs=pairs,\n",
    "    n_clusters=10,  # Number of clusters\n",
    "    top_n=2      # Number of markets per cluster\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quants-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
