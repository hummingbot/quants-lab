{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is necessary to recognize the modules\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.data_sources.clob import CLOBDataSource\n",
    "\n",
    "clob = CLOBDataSource()\n",
    "clob.load_candles_cache(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles = list(clob.candles_cache.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# First, let's prepare the close prices and calculate returns\n",
    "pair_returns = {}\n",
    "for candle in candles:\n",
    "    df = candle.data\n",
    "    if df is not None and not df.empty:\n",
    "        # Get the trading pair from the DataFrame\n",
    "        pair_name = candle.trading_pair\n",
    "        # Calculate returns using pct_change\n",
    "        returns = df[\"close\"].pct_change().dropna()\n",
    "        pair_returns[pair_name] = returns\n",
    "\n",
    "# Create a list of all pairs\n",
    "pairs = list(pair_returns.keys())\n",
    "n_pairs = len(pairs)\n",
    "\n",
    "# Initialize the cointegration matrix\n",
    "cointegration_matrix = pd.DataFrame(np.zeros((n_pairs, n_pairs)), index=pairs, columns=pairs)\n",
    "\n",
    "# Calculate cointegration p-values for each pair combination\n",
    "for i in tqdm(range(n_pairs)):\n",
    "    for j in range(i + 1, n_pairs):\n",
    "        pair1, pair2 = pairs[i], pairs[j]\n",
    "\n",
    "        # Get the returns series\n",
    "        series1 = pair_returns[pair1]\n",
    "        series2 = pair_returns[pair2]\n",
    "\n",
    "        # Align the series to have the same index\n",
    "        series1, series2 = series1.align(series2, join=\"inner\")\n",
    "\n",
    "        if len(series1) > 0:\n",
    "            # Perform cointegration test\n",
    "            _, p_value, _ = coint(series1, series2)\n",
    "\n",
    "            # Fill the matrix (make it symmetric)\n",
    "            cointegration_matrix.iloc[i, j] = p_value\n",
    "            cointegration_matrix.iloc[j, i] = p_value\n",
    "\n",
    "# Fill diagonal with 1s\n",
    "np.fill_diagonal(cointegration_matrix.values, 1)\n",
    "\n",
    "# Display the results\n",
    "print(\"Cointegration p-values matrix:\")\n",
    "print(\"(Lower p-values indicate stronger cointegration)\")\n",
    "cointegration_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# Convert p-values to distances (same as before)\n",
    "distance_matrix = -np.log(cointegration_matrix)\n",
    "distance_matrix[np.isinf(distance_matrix)] = np.max(distance_matrix[~np.isinf(distance_matrix)]) * 2\n",
    "distances_condensed = squareform(distance_matrix)\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "Z = linkage(distances_condensed, method=\"ward\")\n",
    "\n",
    "# Plot dendrogram using plotly\n",
    "fig = ff.create_dendrogram(\n",
    "    Z,\n",
    "    orientation=\"left\",\n",
    ")\n",
    "fig.update_layout(title=\"Hierarchical Clustering Dendrogram\", width=1000, height=800, showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "# Choose number of clusters and create cluster assignments (same as before)\n",
    "n_clusters = 5\n",
    "clusters = fcluster(Z, n_clusters, criterion=\"maxclust\")\n",
    "\n",
    "# Create DataFrame and calculate metrics (same as before)\n",
    "cluster_df = pd.DataFrame({\"trading_pair\": pairs, \"cluster\": clusters})\n",
    "\n",
    "# Calculate volume metrics (same as before)\n",
    "volume_metrics = {}\n",
    "for candle in candles:\n",
    "    if candle.data is not None and not candle.data.empty:\n",
    "        pair_name = candle.trading_pair\n",
    "        avg_volume = candle.data[\"volume\"].mean()\n",
    "        volume_stability = candle.data[\"volume\"].std() / avg_volume\n",
    "        volume_metrics[pair_name] = {\"avg_volume\": avg_volume, \"volume_stability\": volume_stability}\n",
    "\n",
    "cluster_df[\"avg_volume\"] = cluster_df[\"trading_pair\"].map(lambda x: volume_metrics.get(x, {}).get(\"avg_volume\", 0))\n",
    "cluster_df[\"volume_stability\"] = cluster_df[\"trading_pair\"].map(\n",
    "    lambda x: volume_metrics.get(x, {}).get(\"volume_stability\", float(\"inf\"))\n",
    ")\n",
    "\n",
    "# Create scatter plot using plotly\n",
    "fig = px.scatter(\n",
    "    cluster_df,\n",
    "    x=\"avg_volume\",\n",
    "    y=\"volume_stability\",\n",
    "    color=\"cluster\",\n",
    "    hover_data=[\"trading_pair\"],\n",
    "    log_x=True,\n",
    "    log_y=True,\n",
    "    title=\"Clusters by Volume Metrics\",\n",
    ")\n",
    "\n",
    "fig.update_layout(xaxis_title=\"Average Volume\", yaxis_title=\"Volume Stability (lower is better)\", width=1000, height=600)\n",
    "fig.show()\n",
    "\n",
    "# Create heatmap of cointegration matrix using plotly\n",
    "fig = go.Figure(data=go.Heatmap(z=cointegration_matrix, x=pairs, y=pairs, colorscale=\"RdBu_r\", zmin=0, zmax=0.05))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Cointegration P-values Heatmap (Darker colors indicate stronger cointegration)\",\n",
    "    width=1000,\n",
    "    height=1000,\n",
    "    xaxis_tickangle=-45,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Select top pairs (same function as before)\n",
    "def select_top_pairs(cluster_df, n_pairs_per_cluster=3):\n",
    "    selected_pairs = []\n",
    "    for cluster_num in cluster_df[\"cluster\"].unique():\n",
    "        cluster_pairs = cluster_df[cluster_df[\"cluster\"] == cluster_num].copy()\n",
    "        cluster_pairs[\"volume_score\"] = cluster_pairs[\"avg_volume\"] / cluster_pairs[\"volume_stability\"]\n",
    "        top_pairs = cluster_pairs.nlargest(n_pairs_per_cluster, \"volume_score\")\n",
    "        selected_pairs.append(top_pairs)\n",
    "    return pd.concat(selected_pairs)\n",
    "\n",
    "\n",
    "# Select and display top pairs\n",
    "top_pairs = select_top_pairs(cluster_df, n_pairs_per_cluster=3)\n",
    "\n",
    "print(\"\\nTop pairs by cluster:\")\n",
    "for cluster_num in top_pairs[\"cluster\"].unique():\n",
    "    print(f\"\\nCluster {cluster_num}:\")\n",
    "    cluster_result = top_pairs[top_pairs[\"cluster\"] == cluster_num]\n",
    "    print(cluster_result[[\"trading_pair\", \"avg_volume\", \"volume_stability\", \"volume_score\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df.iloc[307]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters_timeseries(candles, Z, pairs, cut_height=None, n_clusters=None):\n",
    "    \"\"\"\n",
    "    Create a line plot of price changes over time, colored by clusters.\n",
    "\n",
    "    Args:\n",
    "        candles: List of candle dataframes\n",
    "        Z: Linkage matrix from hierarchical clustering\n",
    "        pairs: List of trading pair names\n",
    "        cut_height: Height to cut the dendrogram (if None, n_clusters is used)\n",
    "        n_clusters: Number of clusters (used if cut_height is None)\n",
    "    \"\"\"\n",
    "    # Get clusters based on either cut_height or n_clusters\n",
    "    if cut_height is not None:\n",
    "        clusters = fcluster(Z, cut_height, criterion=\"distance\")\n",
    "    else:\n",
    "        clusters = fcluster(Z, n_clusters, criterion=\"maxclust\")\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    plot_data = []\n",
    "    for candle, pair in zip(candles, pairs):\n",
    "        if candle.data is not None and not candle.data.empty:\n",
    "            df = candle.data.copy()\n",
    "            # Calculate cumulative returns to show relative price movement\n",
    "            df[\"cum_returns\"] = (1 + df[\"close\"].pct_change()).cumprod()\n",
    "            df[\"trading_pair\"] = pair\n",
    "            # Find the cluster for this pair\n",
    "            pair_cluster = clusters[pairs.index(pair)]\n",
    "            df[\"cluster\"] = f\"Cluster {pair_cluster}\"\n",
    "            plot_data.append(df)\n",
    "\n",
    "    # Combine all data\n",
    "    combined_df = pd.concat(plot_data)\n",
    "\n",
    "    # Create line plot\n",
    "    fig = px.line(\n",
    "        combined_df,\n",
    "        x=\"timestamp\",\n",
    "        y=\"cum_returns\",\n",
    "        color=\"cluster\",\n",
    "        line_group=\"trading_pair\",\n",
    "        hover_data=[\"trading_pair\", \"close\"],\n",
    "        title=f\"Cumulative Returns Over Time by Cluster ({'Cut Height: ' + str(cut_height) if cut_height else 'Clusters: ' + str(n_clusters)})\",\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=\"Cumulative Returns (1 = start)\",\n",
    "        width=1200,\n",
    "        height=800,\n",
    "        # showlegend=True\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    # Print cluster statistics\n",
    "    print(\"\\nCluster Statistics:\")\n",
    "    cluster_stats = (\n",
    "        combined_df.groupby(\"cluster\").agg({\"cum_returns\": [\"mean\", \"std\", \"count\"], \"trading_pair\": \"nunique\"}).round(4)\n",
    "    )\n",
    "    print(cluster_stats)\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "# Alternative version with normalized prices for easier comparison\n",
    "def plot_clusters_timeseries_normalized(candles, Z, pairs, cut_height=None, n_clusters=None):\n",
    "    \"\"\"\n",
    "    Create a line plot of normalized prices over time, colored by clusters.\n",
    "    All prices are normalized to start at 1 for easier comparison.\n",
    "    \"\"\"\n",
    "    # Get clusters based on either cut_height or n_clusters\n",
    "    if cut_height is not None:\n",
    "        clusters = fcluster(Z, cut_height, criterion=\"distance\")\n",
    "    else:\n",
    "        clusters = fcluster(Z, n_clusters, criterion=\"maxclust\")\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    plot_data = []\n",
    "    for candle, pair in zip(candles, pairs):\n",
    "        if candle.data is not None and not candle.data.empty:\n",
    "            df = candle.data.copy()\n",
    "            # Normalize prices to start at 1\n",
    "            df[\"normalized_price\"] = df[\"close\"] / df[\"close\"].iloc[0]\n",
    "            df[\"trading_pair\"] = pair\n",
    "            # Find the cluster for this pair\n",
    "            pair_cluster = clusters[pairs.index(pair)]\n",
    "            df[\"cluster\"] = f\"Cluster {pair_cluster}\"\n",
    "            plot_data.append(df)\n",
    "\n",
    "    # Combine all data\n",
    "    combined_df = pd.concat(plot_data)\n",
    "\n",
    "    # Create line plot\n",
    "    fig = px.line(\n",
    "        combined_df,\n",
    "        x=\"timestamp\",\n",
    "        y=\"normalized_price\",\n",
    "        color=\"cluster\",\n",
    "        line_group=\"trading_pair\",\n",
    "        hover_data=[\"trading_pair\", \"close\"],\n",
    "        title=f\"Normalized Price Movement by Cluster ({'Cut Height: ' + str(cut_height) if cut_height else 'Clusters: ' + str(n_clusters)})\",\n",
    "    )\n",
    "\n",
    "    fig.update_layout(xaxis_title=\"Time\", yaxis_title=\"Normalized Price (1 = start)\", width=1200, height=800, showlegend=True)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Using cumulative returns\n",
    "clusters = plot_clusters_timeseries(candles, Z, pairs, n_clusters=10)\n",
    "\n",
    "# Using normalized prices\n",
    "clusters = plot_clusters_timeseries_normalized(candles, Z, pairs, n_clusters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_representative_markets(candles, Z, pairs, n_clusters, top_n=1):\n",
    "    \"\"\"\n",
    "    Select representative markets from each cluster based on USD volume and volatility.\n",
    "\n",
    "    Args:\n",
    "        candles: List of candle dataframes\n",
    "        Z: Linkage matrix from hierarchical clustering\n",
    "        pairs: List of trading pair names\n",
    "        n_clusters: Number of clusters to form\n",
    "        top_n: Number of markets per cluster\n",
    "    \"\"\"\n",
    "    # Get cluster assignments\n",
    "    clusters = fcluster(Z, n_clusters, criterion=\"maxclust\")\n",
    "\n",
    "    # Create base DataFrame with cluster assignments\n",
    "    cluster_df = pd.DataFrame({\"trading_pair\": pairs, \"cluster\": clusters})\n",
    "\n",
    "    # Calculate metrics for each market\n",
    "    market_metrics = []\n",
    "    for candle in candles:\n",
    "        if candle.data is not None and not candle.data.empty:\n",
    "            # Calculate USD volume by multiplying volume by price\n",
    "            usd_volume = candle.data[\"volume\"] * candle.data[\"close\"]\n",
    "\n",
    "            metrics = {\n",
    "                \"trading_pair\": candle.trading_pair,\n",
    "                \"avg_usd_volume\": usd_volume.mean(),\n",
    "                \"volatility\": candle.data[\"close\"].pct_change().std(),\n",
    "                \"price_mean\": candle.data[\"close\"].mean(),\n",
    "                \"n_trades\": len(candle.data),\n",
    "                \"volume_stability\": usd_volume.std() / usd_volume.mean() if usd_volume.mean() != 0 else float(\"inf\"),\n",
    "            }\n",
    "            market_metrics.append(metrics)\n",
    "\n",
    "    # Create metrics DataFrame\n",
    "    metrics_df = pd.DataFrame(market_metrics)\n",
    "\n",
    "    # Merge metrics with cluster assignments\n",
    "    cluster_df = cluster_df.merge(metrics_df, on=\"trading_pair\", how=\"left\")\n",
    "\n",
    "    # Normalize metrics\n",
    "    for col in [\"avg_usd_volume\", \"volatility\"]:\n",
    "        cluster_df[f\"{col}_normalized\"] = (cluster_df[col] - cluster_df[col].min()) / (\n",
    "            cluster_df[col].max() - cluster_df[col].min()\n",
    "        )\n",
    "\n",
    "    # Calculate combined score (you can adjust weights here)\n",
    "    cluster_df[\"score\"] = (\n",
    "        cluster_df[\"avg_usd_volume_normalized\"] * 0.6  # Higher weight for volume\n",
    "        + cluster_df[\"volatility_normalized\"] * 0.4  # Lower weight for volatility\n",
    "    )\n",
    "\n",
    "    # Select top markets from each cluster\n",
    "    selected_markets = []\n",
    "    for cluster_num in range(1, n_clusters + 1):\n",
    "        cluster_markets = cluster_df[cluster_df[\"cluster\"] == cluster_num].copy()\n",
    "        top_markets = cluster_markets.nlargest(top_n, \"score\")\n",
    "        selected_markets.append(top_markets)\n",
    "\n",
    "    selected_df = pd.concat(selected_markets)\n",
    "\n",
    "    # Sort by cluster and score\n",
    "    selected_df = selected_df.sort_values([\"cluster\", \"score\"], ascending=[True, False])\n",
    "\n",
    "    # Create visualization\n",
    "    fig = px.scatter(\n",
    "        cluster_df[cluster_df[\"trading_pair\"].isin(selected_df[\"trading_pair\"])],\n",
    "        x=\"avg_usd_volume\",\n",
    "        y=\"volatility\",\n",
    "        color=\"cluster\",\n",
    "        text=\"trading_pair\",\n",
    "        title=f\"Market Selection by USD Volume and Volatility (Top {top_n} per cluster)\",\n",
    "        hover_data=[\"trading_pair\", \"avg_usd_volume\", \"volatility\", \"volume_stability\", \"score\"],\n",
    "        log_x=True,  # Use log scale for volume\n",
    "    )\n",
    "\n",
    "    # Highlight selected markets\n",
    "    selected_pairs = selected_df[\"trading_pair\"].tolist()\n",
    "    for pair in selected_pairs:\n",
    "        market_data = cluster_df[cluster_df[\"trading_pair\"] == pair]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[market_data[\"avg_usd_volume\"].iloc[0]],\n",
    "                y=[market_data[\"volatility\"].iloc[0]],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(symbol=\"star\", size=15, line=dict(width=2, color=\"black\"), showscale=False),\n",
    "                name=f\"Selected: {pair}\",\n",
    "                showlegend=True,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=1000, height=600, showlegend=True, xaxis_title=\"Average USD Volume (log scale)\", yaxis_title=\"Volatility\"\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "    # Print detailed results\n",
    "    print(\"\\nSelected Markets by Cluster:\")\n",
    "    for cluster_num in range(1, n_clusters + 1):\n",
    "        print(f\"\\nCluster {cluster_num}:\")\n",
    "        cluster_results = selected_df[selected_df[\"cluster\"] == cluster_num]\n",
    "        display_cols = [\"trading_pair\", \"avg_usd_volume\", \"volatility\", \"volume_stability\", \"score\"]\n",
    "\n",
    "        # Format the results for better readability\n",
    "        formatted_results = cluster_results[display_cols].copy()\n",
    "        formatted_results[\"avg_usd_volume\"] = formatted_results[\"avg_usd_volume\"].apply(lambda x: f\"${x:,.2f}\")\n",
    "        formatted_results[\"volatility\"] = formatted_results[\"volatility\"].apply(lambda x: f\"{x:.4f}\")\n",
    "        formatted_results[\"volume_stability\"] = formatted_results[\"volume_stability\"].apply(lambda x: f\"{x:.4f}\")\n",
    "        formatted_results[\"score\"] = formatted_results[\"score\"].apply(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "        print(formatted_results.to_string(index=False))\n",
    "\n",
    "    return selected_df\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "selected_markets = select_representative_markets(\n",
    "    candles=candles,\n",
    "    Z=Z,\n",
    "    pairs=pairs,\n",
    "    n_clusters=10,  # Number of clusters\n",
    "    top_n=2,  # Number of markets per cluster\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quants-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
